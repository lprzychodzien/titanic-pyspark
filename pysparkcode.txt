%pyspark
import pyspark.sql.functions as f
from pyspark.sql.types import IntegerType
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit


titanic = spark.read.csv('/data/titanic.csv',header=True,inferSchema=True)
#print((titanic.count(), len(titanic.columns)))
#titanic.printSchema()

titanic = titanic.withColumn("age", titanic["age"].cast(IntegerType()))

titanic = titanic.withColumnRenamed("home.dest","homedest")
titanic = titanic.withColumnRenamed("row.names","rownames")

#for i in titanic.columns:
#    print(i,titanic.where(f.col(i).isNull()).count())
    
titanic = titanic.drop('room','ticket','boat')

#Age
titanic = titanic.withColumn("ageImputed",f.when(f.col("age").isNull(),1).otherwise(0))
meanage = titanic.select(f.mean(f.col('age'))).collect()[0][0]
titanic = titanic.withColumn('age',f.when(f.col('age').isNull(),meanage).otherwise(titanic['age']))

#Embarked and Homedest
titanic = titanic.withColumn("embarkedImputed",f.when(f.col("embarked").isNull(),1).otherwise(0))
titanic = titanic.withColumn("homedestImputed",f.when(f.col("homedest").isNull(),1).otherwise(0))

titanic = titanic.withColumn('homedest',f.when(f.col('homedest').isNull(),'New York, NY').otherwise(titanic['homedest']))
titanic = titanic.withColumn('embarked',f.when(f.col('embarked').isNull(),'Southampton').otherwise(titanic['embarked']))

titanic = StringIndexer(inputCol='embarked',outputCol='embarked_index').fit(titanic).transform(titanic)
titanic = StringIndexer(inputCol='homedest',outputCol='homedest_index').fit(titanic).transform(titanic)

titanic = OneHotEncoder(inputCol="embarked_index", outputCol="embarkedVec").transform(titanic)
titanic = OneHotEncoder(inputCol="homedest_index", outputCol="homedestVec").transform(titanic)

#Pclass
titanic = StringIndexer(inputCol='pclass',outputCol='pclass_index').fit(titanic).transform(titanic)
titanic = OneHotEncoder(inputCol="pclass_index", outputCol="pclassVec").transform(titanic)

df_assembler = VectorAssembler(inputCols=['pclassVec','age','ageImputed','embarkedVec','homedestVec','embarkedImputed','homedestImputed','femalesex'], outputCol='features')
titanic = df_assembler.transform(titanic)
#titanic.printSchema()

#Random Forest
model_titanic = titanic.select(['features','survived'])
train_df,test_df = model_titanic.randomSplit([0.75,0.25])

rf_classifier=RandomForestClassifier(labelCol='survived').fit(train_df)
rf_predictions=rf_classifier.transform(test_df)
print('Accuracy: ', MulticlassClassificationEvaluator(labelCol='survived',metricName='accuracy').evaluate(rf_predictions))
print('Precision: ',MulticlassClassificationEvaluator(labelCol='survived',metricName='weightedPrecision').evaluate(rf_predictions))

rf_classifier2=RandomForestClassifier(labelCol='survived')
paramGrid = ParamGridBuilder()\
    .addGrid(rf_classifier2.maxDepth, [5, 10, 20]) \
    .addGrid(rf_classifier2.maxBins, [20, 32, 50]) \
    .addGrid(rf_classifier2.numTrees, [20, 50, 75]) \
    .addGrid(rf_classifier2.impurity, ["gini", "entropy"]) \
    .addGrid(rf_classifier2.minInstancesPerNode, [1, 5, 10]) \
    .build()
    
tvs = TrainValidationSplit(estimator=rf_classifier2, estimatorParamMaps=paramGrid,evaluator=MulticlassClassificationEvaluator(labelCol='survived'),trainRatio=0.8)
model2 = tvs.fit(train_df)
model2_predictions= model2.transform(test_df)

print('Accuracy: ', MulticlassClassificationEvaluator(labelCol='survived',metricName='accuracy').evaluate(model2_predictions))
print('Precision: ',MulticlassClassificationEvaluator(labelCol='survived',metricName='weightedPrecision').evaluate(model2_predictions))
